import streamlit as st
import google.generativeai as genai
import os
import re
import json
import configparser
from io import BytesIO
from datetime import datetime
from docx import Document
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.shared import Pt
from typing import List, Dict, Any, Optional

# --- H·∫∞NG S·ªê (CONSTANTS) ---

# System instruction: H∆∞·ªõng d·∫´n AI tr·∫£ v·ªÅ JSON chu·∫©n
SYSTEM_INSTRUCTION = (
    "B·∫°n l√† m·ªôt nh√† ph√¢n t√≠ch t√†i li·ªáu k·ªπ thu·∫≠t. Nhi·ªám v·ª• c·ªßa b·∫°n l√† tr√≠ch xu·∫•t th√¥ng tin t·ª´ 'Bi√™n b·∫£n b√†n giao' "
    "v√†o ƒë·ªãnh d·∫°ng JSON. "
    "QUAN TR·ªåNG: Tr∆∞·ªùng 'pk' (Ph·ª• ki·ªán) ph·∫£i l√† m·ªôt danh s√°ch (Array) c√°c chu·ªói, kh√¥ng ƒë∆∞·ª£c g·ªôp th√†nh 1 chu·ªói d√†i. "
    "N·∫øu kh√¥ng c√≥ th√¥ng tin, tr·∫£ v·ªÅ null. Kh√¥ng th√™m Markdown (```json)."
)

# C·∫•u h√¨nh file
CONFIG_FILE_PATH = 'config.ini'
TEMPLATE_FILE = 'bbbg.docx'

# --- C·∫§U H√åNH L·ªåC MODEL ---
DESIRED_MODELS_KEYWORDS = ['pro', 'flash']
EXCLUDE_MODELS_KEYWORDS = ['bison', 'gecko', 'embedding', 'aqa', 'vision', 'legacy']

# T√πy ch·ªânh file output
MAX_FILENAME_LEN = 200
MAX_SERI_DISPLAY = 100
MAX_DEVICES_IN_FILENAME = 2
DEFAULT_FONT_NAME = 'Times New Roman'
DEFAULT_FONT_SIZE = 12

# --- C√ÅC H√ÄM PH·ª§ TR·ª¢ (HELPER FUNCTIONS) ---

def convert_none_to_empty_string(obj: Any) -> Any:
    """ƒê·ªá quy chuy·ªÉn ƒë·ªïi c√°c gi√° tr·ªã None th√†nh chu·ªói r·ªóng."""
    if isinstance(obj, dict):
        return {k: convert_none_to_empty_string(v) for k, v in obj.items()}
    if isinstance(obj, list):
        return [convert_none_to_empty_string(elem) for elem in obj]
    return "" if obj is None else obj

def clean_filename(filename: str) -> str:
    """L√†m s·∫°ch t√™n file."""
    chars_to_remove = (r'[\\/*?":<>|.]')
    cleaned_name = re.sub(chars_to_remove, '', filename)
    if len(cleaned_name) > MAX_FILENAME_LEN:
        cleaned_name = cleaned_name[:MAX_FILENAME_LEN]
    return cleaned_name

def standardize_string(text: Any) -> str:
    """Chu·∫©n h√≥a chu·ªói ti·∫øng Vi·ªát."""
    if not isinstance(text, str):
        return str(text)
    
    text = text.replace('·∫∞', 'ƒÇ').replace('·∫Æ', 'ƒÇ').replace('·∫∂', 'ƒÇ').replace('·∫≤', 'ƒÇ').replace('·∫¥', 'ƒÇ')
    text = text.replace('√à', 'E').replace('√â', 'E').replace('·∫∏', 'E').replace('·∫∫', 'E').replace('·∫º', 'E')
    text = text.replace('·ªÄ', 'E').replace('·∫æ', 'E').replace('·ªÜ', 'E').replace('·ªÇ', 'E').replace('·ªÑ', 'E')
    text = text.replace('√å', 'I').replace('√ç', 'I').replace('·ªä', 'I').replace('·ªà', 'I').replace('ƒ®', 'I')
    text = text.replace('√í', 'O').replace('√ì', 'O').replace('·ªå', 'O').replace('·ªé', 'O').replace('√ï', 'O')
    text = text.replace('·ªí', 'O').replace('·ªê', 'O').replace('·ªò', 'O').replace('·ªî', 'O').replace('·ªñ', 'O')
    text = text.replace('·ªú', 'O').replace('·ªö', 'O').replace('·ª¢', 'O').replace('·ªû', 'O').replace('·ª†', 'O')
    text = text.replace('√ô', 'U').replace('√ö', 'U').replace('·ª§', 'U').replace('·ª¶', 'U').replace('≈®', 'U')
    text = text.replace('·ª™', 'U').replace('·ª®', 'U').replace('·ª∞', 'U').replace('·ª¨', 'U').replace('·ªÆ', 'U')
    text = text.replace('·ª≤', 'Y').replace('√ù', 'Y').replace('·ª¥', 'Y').replace('·ª∂', 'Y').replace('·ª∏', 'Y')
    text = text.replace('ƒê', 'D')
    
    text = text.lower()
    text = text.replace('-', ' ').strip()
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def shorten_company_name(company_name: str) -> str:
    """R√∫t g·ªçn t√™n c√¥ng ty."""
    if not isinstance(company_name, str):
        return str(company_name).strip()

    original_name = company_name.strip()
    name_after_affix_removal = original_name
    
    prefixes = [
        r"C√îNG TY TNHH M·ªòT TH√ÄNH VI√äN", r"C√îNG TY TNHH MTV", r"C√îNG TY TNHH HAI TH√ÄNH VI√äN TR·ªû L√äN",
        r"C√îNG TY C·ªî PH·∫¶N", r"C√îNG TY TNHH", r"C√îNG TY", r"TNHH", r"C·ªî PH·∫¶N",
    ]
    suffixes = [
        r"M·ªòT TH√ÄNH VI√äN", r"MTV", r"HAI TH√ÄNH VI√äN TR·ªû L√äN", r"C·ªî PH·∫¶N", r"TNHH",
    ]
    common_terms = [
        r"TH∆Ø∆†NG M·∫†I V√Ä D·ªäCH V·ª§", r"D·ªäCH V·ª§ V√Ä TH∆Ø∆†NG M·∫†I", r"TM V√Ä DV", r"DV V√Ä TM", r"TM & DV", r"DV & TM",
        r"TM", r"DV", r"C√îNG NGH·ªÜ", r"TH∆Ø∆†NG M·∫†I", r"TRANG THI·∫æT B·ªä", r"Y T·∫æ", r"X√ÇY D·ª∞NG",
        r"ƒê·∫¶U T∆Ø", r"PH√ÅT TRI·ªÇN", r"GI·∫¢I PH√ÅP", r"K·ª∏ THU·∫¨T", r"S·∫¢N XU·∫§T", r"NH·∫¨P KH·∫®U", r"XU·∫§T NH·∫¨P KH·∫®U",
        r"KINH DOANH", r"PH√ÇN PH·ªêI", r"VI·ªÜT NAM"
    ]

    for p in prefixes + suffixes:
        name_after_affix_removal = re.sub(r'^\s*' + re.escape(p) + r'\s*|' + r'\s*' + re.escape(p) + r'\s*$', '', name_after_affix_removal, flags=re.IGNORECASE).strip(" ,.-_&")

    name_after_common_removal = name_after_affix_removal
    for term in common_terms:
        name_after_common_removal = re.sub(r'\b' + re.escape(term) + r'\b', '', name_after_common_removal, flags=re.IGNORECASE).strip()
        name_after_common_removal = re.sub(r'\s+', ' ', name_after_common_removal).strip(" ,.-_&")

    if name_after_common_removal:
        return name_after_common_removal
    if name_after_affix_removal:
        return name_after_affix_removal
    return original_name

# --- C√ÅC H√ÄM X·ª¨ L√ù L√ïI (CORE LOGIC) ---

def group_devices(device_list: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """G·ªôp c√°c thi·∫øt b·ªã gi·ªëng h·ªát nhau."""
    grouped_devices = {}
    
    for item in device_list:
        if not isinstance(item, dict): continue
        
        # X·ª≠ l√Ω 'pk' ƒë·ªÉ l√†m key (v√¨ list kh√¥ng hashable, ph·∫£i chuy·ªÉn v·ªÅ string)
        raw_pk = item.get('pk', '')
        if isinstance(raw_pk, list):
            pk_key = json.dumps(raw_pk, ensure_ascii=False, sort_keys=True)
        else:
            pk_key = str(raw_pk).strip()

        group_key_parts = [
            standardize_string(item.get('ttb', '')).strip(),
            str(item.get('model', '')).strip(),
            str(item.get('hang', '')).strip(),
            str(item.get('nsx', '')).strip(),
            str(item.get('dvt', '')).strip(),
            pk_key # D√πng chu·ªói pk ƒë√£ x·ª≠ l√Ω
        ]
        group_key = tuple(group_key_parts)

        # X·ª≠ l√Ω s·ªë l∆∞·ª£ng (sl)
        current_sl_raw = item.get('sl', '0')
        try:
            cleaned_sl_str = re.sub(r'[^\d.]', '', str(current_sl_raw).strip())
            current_sl = float(cleaned_sl_str) if cleaned_sl_str else 0
        except (ValueError, TypeError):
            current_sl = 0

        # X·ª≠ l√Ω Seri
        current_seri = item.get('seri', [])
        if isinstance(current_seri, str):
            current_seri = [current_seri] if current_seri else []
        elif not isinstance(current_seri, list):
            current_seri = [str(current_seri)] if current_seri is not None else []

        cleaned_current_seri = [str(s).strip() for s in current_seri if s is not None and str(s).strip() != '']

        if group_key not in grouped_devices:
            grouped_devices[group_key] = {
                'ttb': str(item.get('ttb', '')).strip(),
                'model': str(item.get('model', '')).strip(),
                'hang': str(item.get('hang', '')).strip(),
                'nsx': str(item.get('nsx', '')).strip(),
                'dvt': str(item.get('dvt', '')).strip(),
                'pk_raw': raw_pk, # L∆∞u tr·ªØ gi√° tr·ªã g·ªëc (list ho·∫∑c string)
                'total_sl': current_sl,
                'seri': set(cleaned_current_seri)
            }
        else:
            grouped_devices[group_key]['total_sl'] += current_sl
            grouped_devices[group_key]['seri'].update(cleaned_current_seri)

    # Chuy·ªÉn ƒë·ªïi dictionary nh√≥m th√†nh danh s√°ch cu·ªëi c√πng
    final_device_list = []
    for grouped_item in grouped_devices.values():
        seri_string = ""
        if grouped_item['seri']:
            unique_seri = sorted(list(grouped_item['seri']))
            display_seri = unique_seri[:MAX_SERI_DISPLAY]
            seri_string = 'S·ªë seri: ' + ', '.join(display_seri)
            if len(unique_seri) > MAX_SERI_DISPLAY:
                seri_string += f" (v√† {len(unique_seri) - MAX_SERI_DISPLAY} seri kh√°c)"
        
        final_device_list.append({
            'ttb': grouped_item['ttb'],
            'model': grouped_item['model'],
            'hang': grouped_item['hang'],
            'nsx': grouped_item['nsx'],
            'dvt': grouped_item['dvt'],
            'sl': grouped_item['total_sl'],
            'pk': grouped_item['pk_raw'], # Tr·∫£ v·ªÅ gi√° tr·ªã pk g·ªëc
            'seri_text': seri_string
        })
    return final_device_list

def generate_filename(data: Dict[str, Any], grouped_devices: List[Dict[str, Any]]) -> str:
    """T·∫°o t√™n file Word."""
    device_parts = []
    for item in grouped_devices[:MAX_DEVICES_IN_FILENAME]:
        quantity = int(item.get('sl', 0))
        formatted_quantity = f"{quantity:02d}"
        device_name = str(item.get('ttb', '')).strip()
        cleaned_device_name = re.sub(r'[\\/*?":<>|{}\[\]().,_]', '', device_name).strip()
        if cleaned_device_name:
            device_parts.append(f"{formatted_quantity} {cleaned_device_name}")
    device_info_str = "-".join(device_parts) or "ThietBi"

    cty_name_full = str(data.get('cty', 'UnknownCompany')).strip()
    cleaned_cty_name = shorten_company_name(cty_name_full)
    if not cleaned_cty_name:
        cleaned_cty_name = re.sub(r'[\\/*?":<>|{}\[\]()]', '', cty_name_full).strip(" ,.-_&") or "CongTy"

    shd_value = str(data.get('shd', '')).strip()
    shd_main_part = shd_value.split('-', 1)[0].strip() or "SoDinhDanh"
    shd_cleaned = clean_filename(shd_main_part)

    raw_filename = f"{device_info_str}_{cleaned_cty_name}_{shd_cleaned}"
    final_filename_base = re.sub(r'\s+', '_', clean_filename(raw_filename)).strip('_')

    if not final_filename_base or len(final_filename_base) < 3:
        return f"BienBanBanGiao_{cleaned_cty_name}_{shd_cleaned}.docx"
        
    return final_filename_base + '.docx'

def fill_word_template(data: Dict[str, Any], grouped_devices: List[Dict[str, Any]]) -> BytesIO:
    """ƒêi·ªÅn d·ªØ li·ªáu v√†o Word (X·ª≠ l√Ω ph·ª• ki·ªán th√¥ng minh)."""
    try:
        document = Document(TEMPLATE_FILE)
    except Exception as e:
        st.error(f"‚ùå L·ªói m·ªü file m·∫´u '{TEMPLATE_FILE}'.", icon="‚ùå")
        raise e

    # 1. ƒêI·ªÄN B·∫¢NG
    try:
        table = document.tables[0]
        for i in range(len(table.rows) - 1, 0, -1):
            row = table.rows[i]
            row._element.getparent().remove(row._element)

        for count, item in enumerate(grouped_devices, 1):
            ttb_text = str(item.get('ttb', '')).strip()
            model_text = str(item.get('model', '')).strip()
            hang_text = str(item.get('hang', '')).strip()
            nsx_text = str(item.get('nsx', '')).strip()
            dvt_text = str(item.get('dvt', '')).strip()
            sl_text = str(int(item.get('sl', 0))).strip()
            
            # --- X·ª¨ L√ù PH·ª§ KI·ªÜN (C·∫¢I TI·∫æN) ---
            raw_pk = item.get('pk', '')
            pk_lines = []

            # N·∫øu AI tr·∫£ v·ªÅ List (nh·ªù prompt m·ªõi)
            if isinstance(raw_pk, list):
                pk_lines = [str(x).strip() for x in raw_pk if x]
            
            # N·∫øu AI tr·∫£ v·ªÅ String (fallback)
            elif isinstance(raw_pk, str) and raw_pk:
                clean_str = re.sub(r'(c·∫•u h√¨nh bao g·ªìm|bao g·ªìm|chi ti·∫øt c·∫•u h√¨nh):', '', raw_pk, flags=re.IGNORECASE).strip()
                clean_str = clean_str.replace('‚Äì', '-').strip()
                # T√°ch b·∫±ng D·∫•u ch·∫•m ph·∫©y (;) HO·∫∂C Xu·ªëng d√≤ng (\n)
                pk_lines = re.split(r'[;\n]+', clean_str)
            
            formatted_accessories = []
            for acc in pk_lines:
                clean_acc = acc.strip().lstrip('-‚Ä¢+').strip()
                if clean_acc:
                    formatted_accessories.append(f"  + {clean_acc}")
            
            device_info_text = f"{ttb_text}\n- Model: {model_text}\n- H√£ng: {hang_text}\n- NSX: {nsx_text}"
            if formatted_accessories:
                device_info_text += "\n- Ph·ª• ki·ªán:\n" + "\n".join(formatted_accessories)
            # --------------------------------

            new_device_data = [str(count), device_info_text, dvt_text, sl_text, item['seri_text']]

            row = table.add_row()
            for i, cell_text in enumerate(new_device_data):
                ali = WD_ALIGN_PARAGRAPH.CENTER if i in (0, 2, 3) else WD_ALIGN_PARAGRAPH.LEFT
                cell = row.cells[i]
                cell.text = str(cell_text)
                for p in cell.paragraphs:
                    p.alignment = ali
                    for run in p.runs:
                        run.font.name = DEFAULT_FONT_NAME
                        run.font.size = Pt(DEFAULT_FONT_SIZE)

    except IndexError:
        st.error("‚ùå File m·∫´u kh√¥ng c√≥ b·∫£ng.", icon="‚ùå")
        raise

    # 2. REPLACE PLACEHOLDERS
    now = datetime.now()
    replacements = {
        "day": str(now.day),
        "month": str(now.month),
        "year": str(now.year),
    }

    shd_value = str(data.get('shd', '')).strip()
    shd_type = str(data.get('shd_type', 'Kh√°c')).strip()
    if shd_value:
        shd_type_lower = standardize_string(shd_type)
        if any(x in shd_type_lower for x in ['hop dong', 'hd']):
            val = f"D·ª±a theo Hƒê s·ªë: {shd_value}"
        elif any(x in shd_type_lower for x in ['po', 'de nghi']):
            val = f"D·ª±a theo PO: {shd_value}"
        else:
            val = f"D·ª±a theo s·ªë: {shd_value}"
        replacements["shd"] = val
    else:
        replacements["shd"] = ""

    shd_pattern = re.compile(re.escape("shd"), re.IGNORECASE)
    
    for p in document.paragraphs:
        # Replace date
        if any(x in p.text for x in ["day", "month", "year"]):
            for r in p.runs:
                for k, v in replacements.items():
                    if k in r.text:
                        r.text = r.text.replace(k, v)
        # Replace SHD
        if shd_pattern.search(p.text):
            for r in p.runs:
                if shd_pattern.search(r.text):
                    r.text = shd_pattern.sub(replacements["shd"], r.text)

    byte_io = BytesIO()
    document.save(byte_io)
    byte_io.seek(0)
    return byte_io

# --- API & CONFIG ---

@st.cache_resource
def check_prerequisites() -> bool:
    """Ki·ªÉm tra API key v√† file template."""
    if not os.path.exists(CONFIG_FILE_PATH):
        st.error(f"‚ùå Thi·∫øu file '{CONFIG_FILE_PATH}'", icon="‚ùå")
        return False
    
    try:
        config = configparser.ConfigParser()
        config.read(CONFIG_FILE_PATH)
        api_key = config['API']['GEMINI_API_KEY']
        genai.configure(api_key=api_key)
    except Exception:
        st.error("‚ùå L·ªói ƒë·ªçc API Key.", icon="‚ùå")
        return False

    if not os.path.exists(TEMPLATE_FILE):
        st.error(f"‚ùå Thi·∫øu file m·∫´u '{TEMPLATE_FILE}'", icon="‚ùå")
        return False
        
    return True

@st.cache_data
def get_filtered_models() -> List[str]:
    """L·∫•y v√† l·ªçc model Gemini."""
    found = []
    try:
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                name = m.name.lower()
                if any(k in name for k in DESIRED_MODELS_KEYWORDS) and not any(k in name for k in EXCLUDE_MODELS_KEYWORDS):
                    found.append(m.name)
        
        # S·∫Øp x·∫øp ∆∞u ti√™n: 2.5 > 2.0 > 1.5 Pro > Flash
        def priority(nm):
            n = nm.lower()
            if "gemini-3-pro-preview" in n: return 0
            if "gemini-2.5-pro" in n: return 1
            if "gemini-2.5-flash" in n: return 2
            if "gemini-2.5-flash-lite" in n: return 3
            return 4
            
        found.sort(key=priority)
        return found
    except Exception:
        return []

def call_gemini_vision_api(uploaded_file_part, prompt, model_list):
    """G·ªçi API v·ªõi retry qua c√°c model."""
    if not model_list:
        return None

    for model_name in model_list:
        try:
            with st.spinner(f"‚ú® ƒêang d√πng model: {model_name}..."):
                model = genai.GenerativeModel(model_name=model_name, system_instruction=SYSTEM_INSTRUCTION)
                response = model.generate_content([uploaded_file_part, prompt])
                
                text = response.text.strip()
                # Clean Markdown json
                if text.startswith("```json"): text = text[7:]
                if text.endswith("```"): text = text[:-3]
                
                data = json.loads(text.strip())
                st.success(f"‚úÖ Th√†nh c√¥ng v·ªõi model: {model_name}")
                return data
        except Exception as e:
            print(f"Model {model_name} l·ªói: {e}")
            continue
            
    return None

# --- MAIN ---

def main():
    st.set_page_config(page_title="Chuy·ªÉn ƒë·ªïi B√†n giao", layout="centered")
    st.markdown("""<style>.stFileUploader {border: 1px dashed #004aad;}</style>""", unsafe_allow_html=True)
    st.title("Chuy·ªÉn ƒë·ªïi Bi√™n b·∫£n B√†n giao (Fix L·ªói Xu·ªëng d√≤ng)")

    if not check_prerequisites():
        st.stop()

    available_models = get_filtered_models()
    if not available_models:
        st.error("Kh√¥ng t√¨m th·∫•y model Gemini ph√π h·ª£p.", icon="‚ùå")
        st.stop()

    uploaded_file = st.file_uploader("T·∫£i l√™n file (PDF/·∫¢nh)", type=["pdf", "jpg", "png"])

    if uploaded_file:
        st.info(f"üì• ƒêang x·ª≠ l√Ω: {uploaded_file.name}")
        
        file_bytes = uploaded_file.getvalue()
        mime = 'application/pdf' if uploaded_file.name.lower().endswith('.pdf') else 'image/jpeg'
        
        # --- PROMPT M·ªöI: Y√äU C·∫¶U PK L√Ä M·∫¢NG ---
        prompt_content = """
**Y√™u c·∫ßu tr√≠ch xu·∫•t JSON:**
1. **shd**: S·ªë ƒë·ªãnh danh.
2. **shd_type**: Lo·∫°i (H·ª£p ƒë·ªìng, PO...).
3. **cty**: T√™n c√¥ng ty.
4. **ds**: Danh s√°ch thi·∫øt b·ªã:
   - **ttb**: T√™n thi·∫øt b·ªã
   - **model**: Model
   - **hang**: H√£ng
   - **nsx**: N∆∞·ªõc SX
   - **dvt**: ƒêVT
   - **sl**: S·ªë l∆∞·ª£ng
   - **seri**: S·ªë seri
   - **pk**: QUAN TR·ªåNG - Tr·∫£ v·ªÅ m·ªôt DANH S√ÅCH (ARRAY) c√°c chu·ªói ph·ª• ki·ªán. 
     V√≠ d·ª• ƒë√∫ng: ["D√¢y ngu·ªìn (SL: 1)", "C√°p USB (SL: 1)"]
     V√≠ d·ª• sai: "D√¢y ngu·ªìn (SL: 1); C√°p USB (SL: 1)"

**Output JSON:**
{
  "shd": "", "shd_type": "", "cty": "",
  "ds": [
    { "ttb": "", "model": "", "hang": "", "nsx": "", "dvt": "", "sl": 0, "seri": null, "pk": [] }
  ]
}
"""
        
        data = call_gemini_vision_api({'mime_type': mime, 'data': file_bytes}, prompt_content, available_models)

        if data and 'ds' in data:
            data = convert_none_to_empty_string(data)
            grouped = group_devices(data['ds'])
            
            filename = generate_filename(data, grouped)
            word_io = fill_word_template(data, grouped)
            
            st.download_button("‚¨áÔ∏è T·∫£i xu·ªëng file Word", word_io, filename, "application/vnd.openxmlformats-officedocument.wordprocessingml.document")
            st.balloons()
        else:
            st.error("Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c d·ªØ li·ªáu.", icon="‚ùå")

if __name__ == "__main__":
    main()