import streamlit as st
import google.generativeai as genai
import os
import re
import json
import configparser
from io import BytesIO
from datetime import datetime
from docx import Document
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.shared import Pt
from typing import List, Dict, Any, Optional

# --- H·∫∞NG S·ªê (CONSTANTS) ---

# System instruction cho AI
SYSTEM_INSTRUCTION = (
    "B·∫°n l√† m·ªôt nh√† ph√¢n t√≠ch t√†i li·ªáu k·ªπ thu·∫≠t, chuy√™n tr√≠ch xu·∫•t th√¥ng tin chi ti·∫øt t·ª´ 'Bi√™n b·∫£n giao nh·∫≠n - Nghi·ªám thu ki√™m phi·∫øu b·∫£o h√†nh' "
    "v√† c√°c t√†i li·ªáu t∆∞∆°ng t·ª±. Nhi·ªám v·ª• c·ªßa b·∫°n l√† tr√≠ch xu·∫•t c√°c th√¥ng tin sau t·ª´ t·ªáp PDF ho·∫∑c ·∫£nh ƒë∆∞·ª£c cung c·∫•p, ƒë·∫∑c bi·ªát l√† t·ª´ c√°c b·∫£ng bi·ªÉu, "
    "v√† **tr·∫£ v·ªÅ DUY NH·∫§T d∆∞·ªõi ƒë·ªãnh d·∫°ng JSON h·ª£p l·ªá**, kh√¥ng c√≥ b·∫•t k·ª≥ vƒÉn b·∫£n gi·∫£i th√≠ch, k√Ω t·ª± th·ª´a, ho·∫∑c k√Ω hi·ªáu Markdown (nh∆∞ ```json) n√†o kh√°c."
    "S·ª≠ d·ª•ng c√°c vi·∫øt t·∫Øt: shd (gi√° tr·ªã s·ªë ƒë·ªãnh danh), shd_type (lo·∫°i s·ªë ƒë·ªãnh danh), cty, ds, ttb, model, hang, nsx, dvt, sl, seri, pk."
    "L∆∞u √Ω quan tr·ªçng: N·∫øu kh√¥ng t√¨m th·∫•y S·ªë seri ho·∫∑c Ph·ª• ki·ªán, h√£y tr·∫£ v·ªÅ gi√° tr·ªã l√† null cho c√°c tr∆∞·ªùng ƒë√≥."
)

# C·∫•u h√¨nh
CONFIG_FILE_PATH = 'config.ini'
TEMPLATE_FILE = 'bbbg.docx'

# --- C·∫§U H√åNH L·ªåC MODEL ---
# C√°c t·ª´ kh√≥a model b·∫°n mu·ªën ∆∞u ti√™n (v√≠ d·ª•: pro, flash)
DESIRED_MODELS_KEYWORDS = ['pro', 'flash']

# (C·∫¨P NH·∫¨T) Ch·ªâ lo·∫°i tr·ª´ c√°c model c≈©/chuy√™n d·ª•ng
EXCLUDE_MODELS_KEYWORDS = [
    'bison', 'gecko', 'embedding', 'aqa', 'vision', 'legacy'
    # ƒê√£ x√≥a '2.5-pro' kh·ªèi danh s√°ch n√†y
]

# T√πy ch·ªânh file output
MAX_FILENAME_LEN = 200
MAX_SERI_DISPLAY = 100
MAX_DEVICES_IN_FILENAME = 2
DEFAULT_FONT_NAME = 'Times New Roman'
DEFAULT_FONT_SIZE = 12

# --- C√ÅC H√ÄM PH·ª§ TR·ª¢ (HELPER FUNCTIONS) ---
# (C√°c h√†m: convert_none_to_empty_string, clean_filename, 
# standardize_string, shorten_company_name gi·ªØ nguy√™n nh∆∞ c≈©)

def convert_none_to_empty_string(obj: Any) -> Any:
    """ƒê·ªá quy chuy·ªÉn ƒë·ªïi c√°c gi√° tr·ªã None trong dicts v√† lists th√†nh chu·ªói r·ªóng."""
    if isinstance(obj, dict):
        return {k: convert_none_to_empty_string(v) for k, v in obj.items()}
    if isinstance(obj, list):
        return [convert_none_to_empty_string(elem) for elem in obj]
    return "" if obj is None else obj

def clean_filename(filename: str) -> str:
    """Lo·∫°i b·ªè c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát kh·ªèi t√™n file v√† gi·ªõi h·∫°n ƒë·ªô d√†i."""
    chars_to_remove = (r'[\\/*?":<>|.]')
    cleaned_name = re.sub(chars_to_remove, '', filename)
    if len(cleaned_name) > MAX_FILENAME_LEN:
        cleaned_name = cleaned_name[:MAX_FILENAME_LEN]
    return cleaned_name

def standardize_string(text: Any) -> str:
    """Chu·∫©n h√≥a chu·ªói ti·∫øng Vi·ªát: lo·∫°i b·ªè d·∫•u, lowercase, lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a, d·∫•u g·∫°ch ngang."""
    if not isinstance(text, str):
        return str(text)
    
    # Logic lo·∫°i b·ªè d·∫•u (gi·ªØ nguy√™n)
    text = text.replace('·∫∞', 'ƒÇ').replace('·∫Æ', 'ƒÇ').replace('·∫∂', 'ƒÇ').replace('·∫≤', 'ƒÇ').replace('·∫¥', 'ƒÇ')
    text = text.replace('√à', 'E').replace('√â', 'E').replace('·∫∏', 'E').replace('·∫∫', 'E').replace('·∫º', 'E')
    text = text.replace('·ªÄ', 'E').replace('·∫æ', 'E').replace('·ªÜ', 'E').replace('·ªÇ', 'E').replace('·ªÑ', 'E')
    text = text.replace('√å', 'I').replace('√ç', 'I').replace('·ªä', 'I').replace('·ªà', 'I').replace('ƒ®', 'I')
    text = text.replace('√í', 'O').replace('√ì', 'O').replace('·ªå', 'O').replace('·ªé', 'O').replace('√ï', 'O')
    text = text.replace('·ªí', 'O').replace('·ªê', 'O').replace('·ªò', 'O').replace('·ªî', 'O').replace('·ªñ', 'O')
    text = text.replace('·ªú', 'O').replace('·ªö', 'O').replace('·ª¢', 'O').replace('·ªû', 'O').replace('·ª†', 'O')
    text = text.replace('√ô', 'U').replace('√ö', 'U').replace('·ª§', 'U').replace('·ª¶', 'U').replace('≈®', 'U')
    text = text.replace('·ª™', 'U').replace('·ª®', 'U').replace('·ª∞', 'U').replace('·ª¨', 'U').replace('·ªÆ', 'U')
    text = text.replace('·ª≤', 'Y').replace('√ù', 'Y').replace('·ª¥', 'Y').replace('·ª∂', 'Y').replace('·ª∏', 'Y')
    text = text.replace('ƒê', 'D')
    
    text = text.lower()
    text = text.replace('-', ' ').strip()
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def shorten_company_name(company_name: str) -> str:
    """R√∫t g·ªçn t√™n c√¥ng ty (c·∫£i ti·∫øn logic fallback)."""
    if not isinstance(company_name, str):
        return str(company_name).strip()

    original_name = company_name.strip()
    name_after_affix_removal = original_name
    
    prefixes = [
        r"C√îNG TY TNHH M·ªòT TH√ÄNH VI√äN", r"C√îNG TY TNHH MTV", r"C√îNG TY TNHH HAI TH√ÄNH VI√äN TR·ªû L√äN",
        r"C√îNG TY C·ªî PH·∫¶N", r"C√îNG TY TNHH", r"C√îNG TY", r"TNHH", r"C·ªî PH·∫¶N",
    ]
    suffixes = [
        r"M·ªòT TH√ÄNH VI√äN", r"MTV", r"HAI TH√ÄNH VI√äN TR·ªû L√äN", r"C·ªî PH·∫¶N", r"TNHH",
    ]
    common_terms = [
        r"TH∆Ø∆†NG M·∫†I V√Ä D·ªäCH V·ª§", r"D·ªäCH V·ª§ V√Ä TH∆Ø∆†NG M·∫†I", r"TM V√Ä DV", r"DV V√Ä TM", r"TM & DV", r"DV & TM",
        r"TM", r"DV", r"C√îNG NGH·ªÜ", r"TH∆Ø∆†NG M·∫†I", r"TRANG THI·∫æT B·ªä", r"Y T·∫æ", r"X√ÇY D·ª∞NG",
        r"ƒê·∫¶U T∆Ø", r"PH√ÅT TRI·ªÇN", r"GI·∫¢I PH√ÅP", r"K·ª∏ THU·∫¨T", r"S·∫¢N XU·∫§T", r"NH·∫¨P KH·∫®U", r"XU·∫§T NH·∫¨P KH·∫®U",
        r"KINH DOANH", r"PH√ÇN PH·ªêI", r"VI·ªÜT NAM"
    ]

    # 1. Lo·∫°i b·ªè ti·ªÅn t·ªë v√† h·∫≠u t·ªë
    for p in prefixes + suffixes:
        name_after_affix_removal = re.sub(r'^\s*' + re.escape(p) + r'\s*|' + r'\s*' + re.escape(p) + r'\s*$', '', name_after_affix_removal, flags=re.IGNORECASE).strip(" ,.-_&")

    # 2. Lo·∫°i b·ªè c√°c t·ª´ ph·ªï bi·∫øn
    name_after_common_removal = name_after_affix_removal
    for term in common_terms:
        name_after_common_removal = re.sub(r'\b' + re.escape(term) + r'\b', '', name_after_common_removal, flags=re.IGNORECASE).strip()
        name_after_common_removal = re.sub(r'\s+', ' ', name_after_common_removal).strip(" ,.-_&")

    # 3. Logic Fallback: Tr·∫£ v·ªÅ k·∫øt qu·∫£ t·ªët nh·∫•t c√≥ th·ªÉ
    if name_after_common_removal:
        return name_after_common_removal
    if name_after_affix_removal:
        return name_after_affix_removal
    return original_name # Fallback an to√†n nh·∫•t


# --- C√ÅC H√ÄM X·ª¨ L√ù L√ïI (CORE LOGIC FUNCTIONS) ---
# (C√°c h√†m: group_devices, generate_filename, fill_word_template gi·ªØ nguy√™n)

def group_devices(device_list: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """G·ªôp c√°c thi·∫øt b·ªã gi·ªëng h·ªát nhau, t√≠nh t·ªïng s·ªë l∆∞·ª£ng v√† g·ªôp seri."""
    grouped_devices = {}
    
    for item in device_list:
        if not isinstance(item, dict): continue
        
        group_key_parts = [
            standardize_string(item.get('ttb', '')).strip(),
            str(item.get('model', '')).strip(),
            str(item.get('hang', '')).strip(),
            str(item.get('nsx', '')).strip(),
            str(item.get('dvt', '')).strip(),
            str(item.get('pk', '')).strip()
        ]
        group_key = tuple(group_key_parts)

        # X·ª≠ l√Ω s·ªë l∆∞·ª£ng (sl)
        current_sl_raw = item.get('sl', '0')
        try:
            cleaned_sl_str = re.sub(r'[^\d.]', '', str(current_sl_raw).strip())
            current_sl = float(cleaned_sl_str) if cleaned_sl_str else 0
        except (ValueError, TypeError):
            print(f"Warning: Kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi s·ªë l∆∞·ª£ng '{current_sl_raw}' th√†nh s·ªë. D√πng gi√° tr·ªã 0.")
            current_sl = 0

        # X·ª≠ l√Ω Seri
        current_seri = item.get('seri', [])
        if isinstance(current_seri, str):
            current_seri = [current_seri] if current_seri else []
        elif not isinstance(current_seri, list):
            current_seri = [str(current_seri)] if current_seri is not None else []

        cleaned_current_seri = [str(s).strip() for s in current_seri if s is not None and str(s).strip() != '']

        if group_key not in grouped_devices:
            grouped_devices[group_key] = {
                'ttb': str(item.get('ttb', '')).strip(),
                'model': str(item.get('model', '')).strip(),
                'hang': str(item.get('hang', '')).strip(),
                'nsx': str(item.get('nsx', '')).strip(),
                'dvt': str(item.get('dvt', '')).strip(),
                'pk': str(item.get('pk', '')).strip(),
                'total_sl': current_sl,
                'seri': set(cleaned_current_seri)
            }
        else:
            grouped_devices[group_key]['total_sl'] += current_sl
            grouped_devices[group_key]['seri'].update(cleaned_current_seri)

    # Chuy·ªÉn ƒë·ªïi dictionary nh√≥m th√†nh danh s√°ch cu·ªëi c√πng
    final_device_list = []
    for grouped_item in grouped_devices.values():
        seri_string = ""
        if grouped_item['seri']:
            unique_seri = sorted(list(grouped_item['seri']))
            display_seri = unique_seri[:MAX_SERI_DISPLAY]
            seri_string = 'S·ªë seri: ' + ', '.join(display_seri)
            if len(unique_seri) > MAX_SERI_DISPLAY:
                seri_string += f" (v√† {len(unique_seri) - MAX_SERI_DISPLAY} seri kh√°c)"
        
        final_device_list.append({
            'ttb': grouped_item['ttb'],
            'model': grouped_item['model'],
            'hang': grouped_item['hang'],
            'nsx': grouped_item['nsx'],
            'dvt': grouped_item['dvt'],
            'sl': grouped_item['total_sl'],
            'pk': grouped_item['pk'],
            'seri_text': seri_string
        })
    return final_device_list

def generate_filename(data: Dict[str, Any], grouped_devices: List[Dict[str, Any]]) -> str:
    """T·∫°o t√™n file Word ƒë·∫ßu ra d·ª±a tr√™n d·ªØ li·ªáu."""
    
    # 1. Chu·ªói th√¥ng tin thi·∫øt b·ªã
    device_parts = []
    for item in grouped_devices[:MAX_DEVICES_IN_FILENAME]:
        quantity = int(item.get('sl', 0))
        formatted_quantity = f"{quantity:02d}"
        device_name = str(item.get('ttb', '')).strip()
        cleaned_device_name = re.sub(r'[\\/*?":<>|{}\[\]().,_]', '', device_name).strip()
        if cleaned_device_name:
            device_parts.append(f"{formatted_quantity} {cleaned_device_name}")
    device_info_str = "-".join(device_parts) or "ThietBi"

    # 2. T√™n c√¥ng ty
    cty_name_full = str(data.get('cty', 'UnknownCompany')).strip()
    cleaned_cty_name = shorten_company_name(cty_name_full)
    if not cleaned_cty_name:
        cleaned_cty_name = re.sub(r'[\\/*?":<>|{}\[\]()]', '', cty_name_full).strip(" ,.-_&") or "CongTy"

    # 3. SHD (S·ªë ƒë·ªãnh danh)
    shd_value = str(data.get('shd', '')).strip()
    shd_main_part = shd_value.split('-', 1)[0].strip() or "SoDinhDanh"
    shd_cleaned = clean_filename(shd_main_part)

    # 4. K·∫øt h·ª£p
    raw_filename = f"{device_info_str}_{cleaned_cty_name}_{shd_cleaned}"
    final_filename_base = re.sub(r'\s+', '_', clean_filename(raw_filename)).strip('_')

    if not final_filename_base or len(final_filename_base) < 3:
        return f"BienBanBanGiaoNoiBo_Fallback_{cleaned_cty_name}_{shd_cleaned}.docx"
        
    return final_filename_base + '.docx'

def fill_word_template(data: Dict[str, Any], grouped_devices: List[Dict[str, Any]]) -> BytesIO:
    """ƒêi·ªÅn d·ªØ li·ªáu v√†o file Word m·∫´u v√† tr·∫£ v·ªÅ BytesIO."""
    
    try:
        document = Document(TEMPLATE_FILE)
    except Exception as e:
        st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y ho·∫∑c kh√¥ng m·ªü ƒë∆∞·ª£c file m·∫´u '{TEMPLATE_FILE}'. Vui l√≤ng ƒë·∫£m b·∫£o file n√†y n·∫±m c√πng th∆∞ m·ª•c.", icon="‚ùå")
        raise e

    # --- 1. ƒêi·ªÅn b·∫£ng ---
    try:
        table = document.tables[0]
        # X√≥a c√°c h√†ng d·ªØ li·ªáu m·∫´u (tr·ª´ h√†ng ti√™u ƒë·ªÅ ƒë·∫ßu ti√™n)
        for i in range(len(table.rows) - 1, 0, -1):
            row = table.rows[i]
            row._element.getparent().remove(row._element)

        # Th√™m h√†ng m·ªõi
        for count, item in enumerate(grouped_devices, 1):
            ttb_text = str(item.get('ttb', '')).strip()
            model_text = str(item.get('model', '')).strip()
            hang_text = str(item.get('hang', '')).strip()
            nsx_text = str(item.get('nsx', '')).strip()
            dvt_text = str(item.get('dvt', '')).strip()
            sl_text = str(int(item.get('sl', 0))).strip()
            pk_text = str(item.get('pk', '')).strip()

            device_info_text = f"{ttb_text}\n- Model: {model_text}\n- H√£ng: {hang_text}\n- NSX: {nsx_text}"
            
            # X·ª≠ l√Ω Ph·ª• ki·ªán (pk)
            if pk_text:
                pk_text = re.sub(r'(c·∫•u h√¨nh bao g·ªìm|bao g·ªìm|chi ti·∫øt c·∫•u h√¨nh):','', pk_text, flags=re.IGNORECASE).strip()
                pk_text = pk_text.replace('‚Äì', '-').strip()
                accessories = [f"  + {acc.strip().lstrip('-‚Ä¢').strip()}" for acc in pk_text.split('\n') if acc.strip()]
                if accessories:
                    device_info_text += "\n- Ph·ª• ki·ªán:\n" + "\n".join(accessories)

            new_device_data = [
                str(count),
                device_info_text,
                dvt_text,
                sl_text,
                item['seri_text']
            ]

            row = table.add_row()
            for i, cell_text in enumerate(new_device_data):
                ali = WD_ALIGN_PARAGRAPH.CENTER if i in (0, 2, 3) else WD_ALIGN_PARAGRAPH.LEFT
                cell = row.cells[i]
                cell.text = str(cell_text)
                for p in cell.paragraphs:
                    p.alignment = ali
                    for run in p.runs:
                        run.font.name = DEFAULT_FONT_NAME
                        run.font.size = Pt(DEFAULT_FONT_SIZE)

    except IndexError:
        st.error(f"‚ùå File m·∫´u '{TEMPLATE_FILE}' kh√¥ng ch·ª©a b·∫£ng n√†o.", icon="‚ùå")
        raise
    except Exception as e:
        st.error(f"‚ùå L·ªói khi ƒëi·ªÅn d·ªØ li·ªáu v√†o b·∫£ng: {e}", icon="‚ùå")
        raise

    # --- 2. Thay th·∫ø placeholders (Ng√†y th√°ng, SHD) ---
    now = datetime.now()
    replacements = {
        "day": str(now.day),
        "month": str(now.month),
        "year": str(now.year),
    }

    # ƒê·ªãnh d·∫°ng SHD
    shd_value = str(data.get('shd', '')).strip()
    shd_type = str(data.get('shd_type', 'Kh√°c')).strip()
    shd_value_to_replace = ""
    if shd_value:
        shd_type_lower = standardize_string(shd_type)
        if 'hop dong' in shd_type_lower or 'hd' in shd_type_lower:
            shd_value_to_replace = f"D·ª±a theo Hƒê s·ªë: {shd_value}"
        elif 'po' in shd_type_lower or 'de nghi' in shd_type_lower:
            shd_value_to_replace = f"D·ª±a theo PO: {shd_value}"
        else:
            shd_value_to_replace = f"D·ª±a theo s·ªë: {shd_value}"
    
    replacements["shd"] = shd_value_to_replace
    print(f"Gi√° tr·ªã thay th·∫ø cho 'shd': '{shd_value_to_replace}'")

    # Th·ª±c hi·ªán thay th·∫ø
    shd_placeholder_found = False
    shd_pattern = re.compile(re.escape("shd"), re.IGNORECASE)
    
    for p in document.paragraphs:
        # Thay th·∫ø ng√†y th√°ng
        if "day" in p.text or "month" in p.text or "year" in p.text:
            for r in p.runs:
                for key, val in replacements.items():
                    if key in r.text:
                        r.text = r.text.replace(key, val)
        
        # Thay th·∫ø SHD
        if shd_pattern.search(p.text):
            for r in p.runs:
                if shd_pattern.search(r.text):
                    r.text = shd_pattern.sub(shd_value_to_replace, r.text)
                    shd_placeholder_found = True

    if not shd_placeholder_found:
        st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y placeholder 'shd' trong file m·∫´u. S·ªë Hƒê/PO s·∫Ω kh√¥ng ƒë∆∞·ª£c ƒëi·ªÅn.", icon="‚ö†Ô∏è")

    # --- 3. L∆∞u v√†o BytesIO ---
    byte_io = BytesIO()
    document.save(byte_io)
    byte_io.seek(0)
    return byte_io


# --- C√ÅC H√ÄM T∆Ø∆†NG T√ÅC API (API & CONFIG) ---

@st.cache_resource
def check_prerequisites() -> bool:
    """Ki·ªÉm tra API key v√† file template. Tr·∫£ v·ªÅ True n·∫øu t·∫•t c·∫£ ƒë·ªÅu OK."""
    # 1. Ki·ªÉm tra API Key
    api_key_ok = False
    if not os.path.exists(CONFIG_FILE_PATH):
        st.error(f"‚ùå L·ªói c·∫•u h√¨nh: Kh√¥ng t√¨m th·∫•y file '{CONFIG_FILE_PATH}'.", icon="‚ùå")
    else:
        try:
            config = configparser.ConfigParser()
            config.read(CONFIG_FILE_PATH)
            api_key = config['API']['GEMINI_API_KEY']
            genai.configure(api_key=api_key)
            print("ƒê√£ ƒë·ªçc API Key v√† c·∫•u h√¨nh genai.")
            api_key_ok = True
        except Exception as e:
            st.error(f"‚ùå L·ªói c·∫•u h√¨nh: Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c API Key t·ª´ '{CONFIG_FILE_PATH}': {e}", icon="‚ùå")

    # 2. Ki·ªÉm tra file m·∫´u Word
    template_ok = os.path.exists(TEMPLATE_FILE)
    if not template_ok:
        st.error(f"‚ùå L·ªói file m·∫´u: Kh√¥ng t√¨m th·∫•y file '{TEMPLATE_FILE}'. Vui l√≤ng ƒë·∫£m b·∫£o file n√†y n·∫±m c√πng th∆∞ m·ª•c.", icon="‚ùå")

    return api_key_ok and template_ok

@st.cache_data
def get_filtered_models() -> List[str]:
    """
    (C·∫¨P NH·∫¨T) L·∫•y danh s√°ch model t·ª´ API v√† l·ªçc ra c√°c model ph√π h·ª£p.
    ∆Øu ti√™n c√°c model Pro m·∫°nh nh·∫•t (2.5 -> 2.0 -> 1.5).
    """
    print("ƒêang truy v·∫•n danh s√°ch model t·ª´ API...")
    found_models = []
    try:
        for m in genai.list_models():
            # Ki·ªÉm tra xem model c√≥ h·ªó tr·ª£ 'generateContent' kh√¥ng
            if 'generateContent' in m.supported_generation_methods:
                model_name = m.name.lower() # V√≠ d·ª•: 'models/gemini-1.5-pro-latest'
                
                # 1. L·ªçc
                has_desired = any(k in model_name for k in DESIRED_MODELS_KEYWORDS)
                has_excluded = any(k in model_name for k in EXCLUDE_MODELS_KEYWORDS)
                
                # Ch·ªâ th√™m v√†o danh s√°ch n·∫øu n√≥ ch·ª©a t·ª´ kh√≥a mong mu·ªën (pro, flash)
                # V√Ä KH√îNG ch·ª©a t·ª´ kh√≥a lo·∫°i tr·ª´ (bison, gecko, ...)
                if has_desired and not has_excluded:
                    found_models.append(m.name) # Th√™m t√™n model ƒë·∫ßy ƒë·ªß
        
        # (M·ªöI) Logic s·∫Øp x·∫øp ∆∞u ti√™n (Pro 2.5 -> 2.0 -> 1.5 -> Flash 1.5)
        def get_priority(model_name):
            """H√†m tr·∫£ v·ªÅ tuple ƒë·ªÉ sort, s·ªë nh·ªè h∆°n = ∆∞u ti√™n cao h∆°n."""
            name = model_name.lower()
            
            # ∆Øu ti√™n 1: Gemini 2.5 Pro (preview, latest, v.v.)
            if "gemini-2.5-pro" in name:
                return (0, "preview" not in name, name) # ∆Øu ti√™n preview (0, False, ...)
            
            # ∆Øu ti√™n 2: Gemini 2.0 Pro (n·∫øu c√≥)
            if "gemini-2.0-pro" in name:
                return (1, "latest" not in name, name) # ∆Øu ti√™n latest
            
            # ∆Øu ti√™n 3: Gemini 1.5 Pro
            if "gemini-1.5-pro-latest" in name:
                return (2, name)
            if "gemini-1.5-pro" in name:
                return (3, name)
            
            # ∆Øu ti√™n 4: Gemini 1.5 Flash
            if "gemini-1.5-flash-latest" in name:
                return (4, name)
            if "gemini-1.5-flash" in name:
                return (5, name)
            
            # M·∫∑c ƒë·ªãnh
            return (6, name)

        # S·∫Øp x·∫øp danh s√°ch model d·ª±a tr√™n h√†m ∆∞u ti√™n
        found_models.sort(key=get_priority)
        
        print(f"ƒê√£ l·ªçc v√† s·∫Øp x·∫øp (∆Øu ti√™n Pro 2.5) {len(found_models)} model. Th·ª© t·ª± ∆∞u ti√™n: {found_models}")
        
        if not found_models:
             print("Kh√¥ng t√¨m th·∫•y model n√†o. ƒê·∫£m b·∫£o DESIRED/EXCLUDE_KEYWORDS ƒë√∫ng.")
             st.warning("Kh√¥ng t√¨m th·∫•y model n√†o ph√π h·ª£p sau khi l·ªçc. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u h√¨nh l·ªçc.")
             
        return found_models

    except Exception as e:
        st.error(f"L·ªói khi truy v·∫•n danh s√°ch model: {e}", icon="‚ùå")
        print(f"L·ªói khi g·ªçi genai.list_models(): {e}")
        return [] # Tr·∫£ v·ªÅ danh s√°ch r·ªóng n·∫øu l·ªói

def call_gemini_vision_api(
    uploaded_file_part: Dict[str, Any], 
    prompt: str,
    model_list: List[str]
) -> Optional[Dict[str, Any]]:
    """
    (C·∫¨P NH·∫¨T) G·ªçi API Gemini v·ªõi danh s√°ch model ƒë√£ l·ªçc, tr·∫£ v·ªÅ dict JSON ho·∫∑c None.
    """
    data = None
    raw_ai_response = ""
    
    if not model_list:
        st.error("‚ùå Kh√¥ng t√¨m th·∫•y model n√†o ph√π h·ª£p ƒë·ªÉ x·ª≠ l√Ω. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u h√¨nh l·ªçc model.", icon="‚ùå")
        return None

    for model_name in model_list:
        try:
            with st.spinner(f"‚ú® ƒêang tr√≠ch xu·∫•t d·ªØ li·ªáu b·∫±ng model: **{model_name}**..."):
                model = genai.GenerativeModel(
                    model_name=model_name,
                    system_instruction=SYSTEM_INSTRUCTION
                )
                response = model.generate_content(
                    contents=[uploaded_file_part, prompt]
                )
                raw_ai_response = response.text
                print(f"Ph·∫£n h·ªìi th√¥ t·ª´ {model_name}: {raw_ai_response}")

                # L√†m s·∫°ch v√† parse JSON
                cleaned_response = raw_ai_response.strip().removeprefix("```json").removesuffix("```").strip()
                data = json.loads(cleaned_response)
                
                st.success(f"Tr√≠ch xu·∫•t th√†nh c√¥ng b·∫±ng model: **{model_name}**!")
                return data # Th√†nh c√¥ng, tr·∫£ v·ªÅ d·ªØ li·ªáu
                
        except json.JSONDecodeError as json_err:
            st.warning(f"‚ö†Ô∏è Model {model_name} kh√¥ng tr·∫£ v·ªÅ JSON h·ª£p l·ªá: {json_err}. ƒêang th·ª≠ model ti·∫øp theo...", icon="‚ö†Ô∏è")
            print(f"Model {model_name} l·ªói JSON: {json_err}")
        except Exception as api_err:
            # Ki·ªÉm tra xem c√≥ ph·∫£i l·ªói Quota 429 kh√¥ng
            if "429" in str(api_err) and "quota" in str(api_err).lower():
                 st.warning(f"‚ö†Ô∏è Model {model_name} b√°o l·ªói Quota (429). ƒêang th·ª≠ model ti·∫øp theo...", icon="‚ö†Ô∏è")
                 print(f"Model {model_name} l·ªói Quota 429.")
            else:
                # L·ªói API kh√°c
                st.warning(f"‚ö†Ô∏è Model {model_name} g·∫∑p l·ªói API: {api_err}. ƒêang th·ª≠ model ti·∫øp theo...", icon="‚ö†Ô∏è")
                print(f"Model {model_name} l·ªói API: {api_err}")

    # N·∫øu v√≤ng l·∫∑p k·∫øt th√∫c m√† kh√¥ng th√†nh c√¥ng
    st.error("‚ùå T·∫•t c·∫£ c√°c model ƒë√£ th·ª≠ ƒë·ªÅu th·∫•t b·∫°i.", icon="‚ùå")
    if raw_ai_response:
        st.text_area("Ph·∫£n h·ªìi g·ªëc cu·ªëi c√πng (g√¢y l·ªói):", raw_ai_response, height=200)
    return None

# --- H√ÄM CH√çNH (MAIN FUNCTION) ---

def main():
    st.set_page_config(page_title="Chuy·ªÉn ƒë·ªïi B√†n giao", layout="centered")
    
    # --- CSS T√πy ch·ªânh ---
    st.markdown("""
    <style>
    .stFileUploader {
        padding: 1rem;
        border: 1px dashed #004aad;
        border-radius: 0.5rem;
        background-color: rgba(230, 240, 255, 0.1);
        margin-bottom: 1.5rem;
    }
    .stProgress > div > div > div > div {
        background-color: #4CAF50;
    }
    div[data-testid="stVerticalBlock"] {
        gap: 1.5rem;
    }
    h1 {
        text-align: center;
    }
    </style>
    """, unsafe_allow_html=True)

    st.title("C√¥ng c·ª• Chuy·ªÉn ƒë·ªïi Bi√™n b·∫£n B√†n giao")

    # --- 1. KI·ªÇM TRA ƒêI·ªÄU KI·ªÜN TI√äN QUY·∫æT ---
    if not check_prerequisites():
        st.warning("Vui l√≤ng kh·∫Øc ph·ª•c c√°c l·ªói c·∫•u h√¨nh tr√™n ƒë·ªÉ ti·∫øp t·ª•c.", icon="‚ö†Ô∏è")
        st.stop() # D·ª´ng ·ª©ng d·ª•ng n·∫øu thi·∫øu API key ho·∫∑c file m·∫´u

    st.markdown(f"‚ÑπÔ∏è **L∆∞u √Ω:** File m·∫´u Word (`{TEMPLATE_FILE}`) ƒë√£ ƒë∆∞·ª£c t√¨m th·∫•y.")
    
    # --- (M·ªöI) L·∫§Y DANH S√ÅCH MODEL SAU KHI QUA B∆Ø·ªöC KI·ªÇM TRA ---
    available_models = get_filtered_models()
    if not available_models:
        st.error("Kh√¥ng th·ªÉ l·∫•y ƒë∆∞·ª£c danh s√°ch model ph√π h·ª£p t·ª´ Google. Vui l√≤ng ki·ªÉm tra API key v√† k·∫øt n·ªëi.", icon="‚ùå")
        st.stop()

    # --- 2. GIAO DI·ªÜN T·∫¢I L√äN ---
    st.subheader("T·∫£i l√™n Bi√™n b·∫£n b√†n giao g·ªëc (PDF ho·∫∑c ·∫¢nh)")
    uploaded_file = st.file_uploader(
        "Ch·ªçn file Bi√™n b·∫£n b√†n giao c√¥ng ty (PDF ho·∫∑c ·∫¢nh)",
        type=["pdf", "jpg", "jpeg", "png"],
        label_visibility="collapsed",
        key="file_uploader"
    )

    if not uploaded_file:
        st.info("‚¨ÜÔ∏è Vui l√≤ng ch·ªçn m·ªôt file PDF/·∫¢nh ƒë·ªÉ b·∫Øt ƒë·∫ßu.", icon="üìÑ")
        st.stop()

    # --- 3. X·ª¨ L√ù FILE (CH·ªà CH·∫†Y KHI C√ì FILE) ---
    try:
        st.info(f"üì• ƒêang x·ª≠ l√Ω file: **{uploaded_file.name}**", icon="‚è≥")
        
        # 3.1. ƒê·ªçc file v√† chu·∫©n b·ªã
        file_bytes = uploaded_file.getvalue()
        file_extension = uploaded_file.name.split('.')[-1].lower()
        
        if file_extension == 'pdf':
            file_mime_type = 'application/pdf'
        elif file_extension in ['jpg', 'jpeg']:
            file_mime_type = 'image/jpeg'
        elif file_extension == 'png':
            file_mime_type = 'image/png'
        else:
            st.error("ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£.", icon="‚ùå")
            st.stop()

        uploaded_file_part = {
            'mime_type': file_mime_type,
            'data': file_bytes
        }

        # 3.2. Prompt cho AI
        prompt_content = """
**Th√¥ng tin c·∫ßn tr√≠ch xu·∫•t:**
- **S·ªë ƒë·ªãnh danh ch√≠nh (shd):** Gi√° tr·ªã s·ªë ho·∫∑c m√£ c·ªßa bi√™n b·∫£n.
- **Lo·∫°i s·ªë ƒë·ªãnh danh (shd_type):** X√°c ƒë·ªãnh lo·∫°i c·ªßa 'shd'.
- **T√™n c√¥ng ty b√†n giao (cty):** T√™n ƒë·∫ßy ƒë·ªß c·ªßa c√¥ng ty b√™n giao (B√™n A).
- **Danh s√°ch thi·∫øt b·ªã (ds):** M·∫£ng c√°c ƒë·ªëi t∆∞·ª£ng JSON (ttb, model, hang, nsx, dvt, sl, seri, pk).

**C·∫•u tr√∫c JSON ƒë·∫ßu ra ph·∫£i tu√¢n th·ªß nghi√™m ng·∫∑t:**
{
  "shd": "Gi√° tr·ªã s·ªë/m√£",
  "shd_type": "H·ª£p ƒë·ªìng" ho·∫∑c "PO" ho·∫∑c "ƒê·ªÅ ngh·ªã" ho·∫∑c "Kh√°c",
  "cty": "T√™n c√¥ng ty",
  "ds": [
    {
      "ttb": "T√™n thi·∫øt b·ªã",
      "model": "Model thi·∫øt b·ªã",
      "hang": "H√£ng s·∫£n xu·∫•t",
      "nsx": "N∆∞·ªõc s·∫£n xu·∫•t",
      "dvt": "ƒê∆°n v·ªã t√≠nh",
      "sl": "S·ªë l∆∞·ª£ng",
      "seri": "S·ªë seri" ho·∫∑c ["seri1", "seri2"] ho·∫∑c null,
      "pk": "Chi ti·∫øt ph·ª• ki·ªán" ho·∫∑c null
    }
  ]
}
"""

        # 3.3. G·ªçi API Gemini (v·ªõi danh s√°ch model ƒë√£ l·ªçc)
        data = call_gemini_vision_api(uploaded_file_part, prompt_content, available_models)

        if not data:
            st.error("Kh√¥ng th·ªÉ tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ file.", icon="‚ùå")
            st.stop()

        # 3.4. Ki·ªÉm tra d·ªØ li·ªáu AI tr·∫£ v·ªÅ
        if 'ds' not in data or not isinstance(data.get('ds'), list):
            st.error("‚ùå Ph·∫£n h·ªìi t·ª´ AI kh√¥ng ch·ª©a danh s√°ch thi·∫øt b·ªã ('ds') h·ª£p l·ªá.", icon="‚ùå")
            st.text_area("D·ªØ li·ªáu AI tr·∫£ v·ªÅ:", json.dumps(data, indent=2, ensure_ascii=False), height=200)
            st.stop()

        # 3.5. X·ª≠ l√Ω v√† t·∫°o file Word
        st.info("‚úçÔ∏è ƒêang t·∫°o file Word...", icon="‚è≥")
        
        # Chuy·ªÉn ƒë·ªïi None -> ""
        data = convert_none_to_empty_string(data)
        
        # G·ªôp nh√≥m thi·∫øt b·ªã
        grouped_devices = group_devices(data['ds'])
        if not grouped_devices:
            st.warning("‚ö†Ô∏è Kh√¥ng c√≥ thi·∫øt b·ªã h·ª£p l·ªá n√†o ƒë∆∞·ª£c t√¨m th·∫•y sau khi g·ªôp nh√≥m.", icon="‚ö†Ô∏è")
            st.stop()

        # T·∫°o t√™n file
        filename = generate_filename(data, grouped_devices)
        
        # ƒêi·ªÅn v√†o file Word
        word_bytes_io = fill_word_template(data, grouped_devices)

        # 3.6. Hi·ªÉn th·ªã n√∫t T·∫£i xu·ªëng
        st.download_button(
            label=f"‚úÖ T·∫£i xu·ªëng file: {filename}",
            data=word_bytes_io,
            file_name=filename,
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        )
        st.success(f"üéâ ƒê√£ t·∫°o file th√†nh c√¥ng: **{filename}**", icon="‚úÖ")

    except Exception as e:
        st.error(f"‚ùå ƒê√£ c√≥ l·ªói kh√¥ng mong mu·ªën x·∫£y ra trong qu√° tr√¨nh x·ª≠ l√Ω: {e}", icon="‚ùå")
        print(f"L·ªói kh√¥ng mong mu·ªën trong h√†m main: {e}")

if __name__ == "__main__":
    main()