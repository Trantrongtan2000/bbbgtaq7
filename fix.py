import google.generativeai as genai
import streamlit as st
import os
from docx import Document
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.shared import Pt
import tempfile
import json
import re
import configparser
from io import BytesIO

def clean_filename(filename):
    """Lo·∫°i b·ªè c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát kh·ªèi t√™n file v√† gi·ªõi h·∫°n ƒë·ªô d√†i."""
    chars_to_remove = (r'[\\/*?":<>|.]')
    cleaned_name = re.sub(chars_to_remove, '', filename)
    max_len = 200 # Gi·ªõi h·∫°n ƒë·ªô d√†i t√™n file
    if len(cleaned_name) > max_len:
        cleaned_name = cleaned_name[:max_len]
    return cleaned_name

# --- H√†m chu·∫©n h√≥a k√Ω t·ª± ti·∫øng Vi·ªát v√† l√†m s·∫°ch cho grouping/filename ---
def standardize_string(text):
    """Chu·∫©n h√≥a chu·ªói: lo·∫°i b·ªè d·∫•u, chuy·ªÉn lowercase, lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a, d·∫•u g·∫°ch ngang."""
    if not isinstance(text, str):
        return str(text)
    text = text.replace('·∫∞', 'ƒÇ').replace('·∫Æ', 'ƒÇ').replace('·∫∂', 'ƒÇ').replace('·∫≤', 'ƒÇ').replace('·∫¥', 'ƒÇ')
    text = text.replace('√à', 'E').replace('√â', 'E').replace('·∫∏', 'E').replace('·∫∫', 'E').replace('·∫º', 'E')
    text = text.replace('·ªÄ', 'E').replace('·∫æ', 'E').replace('·ªÜ', 'E').replace('·ªÇ', 'E').replace('·ªÑ', 'E')
    text = text.replace('√å', 'I').replace('√ç', 'I').replace('·ªä', 'I').replace('·ªà', 'I').replace('ƒ®', 'I')
    text = text.replace('√í', 'O').replace('√ì', 'O').replace('·ªå', 'O').replace('·ªé', 'O').replace('√ï', 'O')
    text = text.replace('·ªí', 'O').replace('·ªê', 'O').replace('·ªò', 'O').replace('·ªî', 'O').replace('·ªñ', 'O')
    text = text.replace('·ªú', 'O').replace('·ªö', 'O').replace('·ª¢', 'O').replace('·ªû', 'O').replace('·ª†', 'O')
    text = text.replace('√ô', 'U').replace('√ö', 'U').replace('·ª§', 'U').replace('·ª¶', 'U').replace('≈®', 'U')
    text = text.replace('·ª™', 'U').replace('·ª®', 'U').replace('·ª∞', 'U').replace('·ª¨', 'U').replace('·ªÆ', 'U')
    text = text.replace('·ª≤', 'Y').replace('√ù', 'Y').replace('·ª¥', 'Y').replace('·ª∂', 'Y').replace('·ª∏', 'Y')
    text = text.replace('ƒê', 'D')

    text = text.lower()
    text = re.sub(r'\s+', ' ', text).strip()
    text = text.replace('-', ' ').strip()
    text = re.sub(r'\s+', ' ', text).strip()

    return text

# --- H√†m r√∫t g·ªçn t√™n c√¥ng ty ---
def shorten_company_name(company_name):
    """R√∫t g·ªçn t√™n c√¥ng ty b·∫±ng c√°ch lo·∫°i b·ªè c√°c ti·ªÅn t·ªë v√† h·∫≠u t·ªë ph·ªï bi·∫øn."""
    if not isinstance(company_name, str):
        return str(company_name).strip()

    cleaned_name = company_name.strip()
    upper_name = cleaned_name.upper()

    prefixes = [
        "C√îNG TY TNHH M·ªòT TH√ÄNH VI√äN", "C√îNG TY TNHH MTV", "C√îNG TY TNHH HAI TH√ÄNH VI√äN TR·ªû L√äN",
        "C√îNG TY C·ªî PH·∫¶N", "C√îNG TY TNHH", "C√îNG TY", "TNHH", "C·ªî PH·∫¶N",
    ]
    suffixes = [
        "M·ªòT TH√ÄNH VI√äN", "MTV", "HAI TH√ÄNH VI√äN TR·ªû L√äN", "C·ªî PH·∫¶N", "TNHH",
    ]
    common_terms = [
        "TH∆Ø∆†NG M·∫†I V√Ä D·ªäCH V·ª§", "D·ªäCH V·ª§ V√Ä TH∆Ø∆†NG M·∫†I", "TM V√Ä DV", "DV V√Ä TM", "TM & DV", "DV & TM",
        "TM", "DV", "C√îNG NGH·ªÜ", "TH∆Ø∆†NG M·∫†I", "TRANG THI·∫æT B·ªä", "Y T·∫æ", "X√ÇY D·ª∞NG",
        "ƒê·∫¶U T∆Ø", "PH√ÅT TRI·ªÇN", "GI·∫¢I PH√ÅP", "K·ª∏ THU·∫¨T", "S·∫¢N XU·∫§T", "NH·∫¨P KH·∫®U", "XU·∫§T NH·∫¨P KH·∫®U",
        "KINH DOANH", "PH√ÇN PH·ªêI", "VI·ªÜT NAM"
    ]

    for prefix in prefixes:
        pattern = r'^' + re.escape(prefix) + r'\s*'
        cleaned_name = re.sub(pattern, '', cleaned_name, flags=re.IGNORECASE).strip(" ,.-_&")

    for suffix in suffixes:
         pattern = r'\s*' + re.escape(suffix) + r'$'
         cleaned_name = re.sub(pattern, '', cleaned_name, flags=re.IGNORECASE).strip(" ,.-_&")

    for term in common_terms:
         pattern = r'\b' + re.escape(term) + r'\b'
         cleaned_name = re.sub(pattern, '', cleaned_name, flags=re.IGNORECASE).strip()
         cleaned_name = re.sub(r'\s+', ' ', cleaned_name).strip()

    cleaned_name = cleaned_name.strip(" ,.-_&")

    if not cleaned_name:
        words = company_name.strip().split()
        if words:
             fallback_name = " ".join(words[-3:])
             return fallback_name.strip(" ,.-_&")

        return company_name.strip()

    return cleaned_name

# --- K·∫øt th√∫c h√†m r√∫t g·ªçn t√™n c√¥ng ty ---

# --- C·∫•u h√¨nh giao di·ªán v√† CSS ---
# ƒê·ªïi layout t·ª´ wide sang centered
st.set_page_config(page_title="Chuy·ªÉn ƒë·ªïi B√†n giao", layout="centered")

st.markdown("""
<style>
/* Lo·∫°i b·ªè m√†u n·ªÅn t√πy ch·ªânh ƒë·ªÉ s·ª≠ d·ª•ng m√†u n·ªÅn m·∫∑c ƒë·ªãnh c·ªßa Streamlit Theme (Dark/Light) */
/* .stApp { background-color: #f0f2f6; } */

/* Lo·∫°i b·ªè padding ngang t√πy ch·ªânh ƒë·ªÉ Streamlit centered layout qu·∫£n l√Ω */
.css-1lcbmhc { /* ƒê√¢y l√† class cho main content container */
    padding-top: 0rem;
    padding-bottom: 10rem;
    /* Lo·∫°i b·ªè padding-left v√† padding-right */
    /* padding-left: 5%; */
    /* padding-right: 5%; */
}

/* Lo·∫°i b·ªè m√†u ch·ªØ t√πy ch·ªânh ƒë·ªÉ s·ª≠ d·ª•ng m√†u ch·ªØ m·∫∑c ƒë·ªãnh c·ªßa Streamlit Theme */
/* .stMarkdown h1, .stMarkdown h2, .stMarkdown h3 { color: #0e1117; } */

/* Ki·ªÉu d√°ng cho File Uploader */
.stFileUploader {
    padding: 1rem;
    border: 1px dashed #004aad; /* Vi·ªÅn n√©t ƒë·ª©t */
    border-radius: 0.5rem;
    background-color: rgba(230, 240, 255, 0.1); /* N·ªÅn nh·∫π c√≥ ƒë·ªô trong su·ªët, ph√π h·ª£p v·ªõi n·ªÅn t·ªëi */
    margin-bottom: 1.5rem;
}

/* M√†u cho Progress Bar */
.stProgress > div > div > div > div {
    background-color: #4CAF50; /* M√†u xanh l√° */
}

/* Kho·∫£ng c√°ch gi·ªØa c√°c Block */
div[data-testid="stVerticalBlock"] {
    gap: 1.5rem;
}

/* Padding cho block container (c√≥ th·ªÉ th·ª´a n·∫øu .css-1lcbmhc ƒë√£ x·ª≠ l√Ω) */
.reportview-container .main .block-container {
    padding-top: 2rem;
    padding-bottom: 2rem;
}

/* CƒÉn gi·ªØa ti√™u ƒë·ªÅ */
h1 {
    text-align: center;
}


</style>
""", unsafe_allow_html=True)
# --- K·∫øt th√∫c C·∫•u h√¨nh giao di·ªán v√† CSS ---


st.title("C√¥ng c·ª• Chuy·ªÉn ƒë·ªïi Bi√™n b·∫£n B√†n giao")
# S·ª≠ d·ª•ng c·ªôt ƒë·ªÉ b·ªë c·ª•c ph·∫ßn upload v√† th√¥ng tin (v·∫´n gi·ªØ c·ªôt ƒë·ªÉ t·ªï ch·ª©c)
col1, col2 = st.columns([2, 1]) # T·ª∑ l·ªá c·ªôt


st.subheader("T·∫£i l√™n Bi√™n b·∫£n b√†n giao g·ªëc (PDF)")
file_name = st.file_uploader("Ch·ªçn file PDF Bi√™n b·∫£n b√†n giao c√¥ng ty", type="pdf", label_visibility="collapsed", key="pdf_uploader")


temp_file_path = None

if file_name is not None:
    try:
        st.info(f"üì• ƒêang t·∫£i l√™n v√† x·ª≠ l√Ω file: **{file_name.name}**", icon="‚è≥")
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as temp_file:
            temp_file.write(file_name.getvalue())
            temp_file_path = temp_file.name
            print(f"File t·∫°m ƒë∆∞·ª£c l∆∞u t·∫°i: {temp_file_path}")

        with st.spinner("‚ú® ƒêang tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ file PDF..."):
            sample_pdf = genai.upload_file(path=temp_file_path)
            print(f"File ƒë√£ t·∫£i l√™n Google AI: {sample_pdf.name}")

            model = genai.GenerativeModel(
                model_name='gemini-2.0-flash-lite',
                system_instruction=[
                    "B·∫°n l√† m·ªôt nh√† ph√¢n t√≠ch t√†i li·ªáu k·ªπ thu·∫≠t, chuy√™n tr√≠ch xu·∫•t th√¥ng tin chi ti·∫øt t·ª´ 'Bi√™n b·∫£n giao nh·∫≠n - Nghi·ªám thu ki√™m phi·∫øu b·∫£o h√†nh' v√† c√°c t√†i li·ªáu t∆∞∆°ng t·ª±.",
                    "Nhi·ªám v·ª• c·ªßa b·∫°n l√† hi·ªÉu d·ªØ li·ªáu trong t·ªáp PDF ƒë∆∞·ª£c cung c·∫•p, ƒë·∫∑c bi·ªát l√† t·ª´ c√°c b·∫£ng bi·ªÉu, v√† tr√≠ch xu·∫•t c√°c th√¥ng tin ƒë∆∞·ª£c y√™u c·∫ßu d∆∞·ªõi ƒë·ªãnh d·∫°ng JSON.",
                    "Tr√≠ch xu·∫•t th√¥ng tin ch√≠nh x√°c t·ª´ c√°c b·∫£ng, bao g·ªìm danh s√°ch thi·∫øt b·ªã. ƒê·ªëi v·ªõi m·ªói thi·∫øt b·ªã trong b·∫£ng, h√£y x√°c ƒë·ªãnh: T√™n thi·∫øt b·ªã (d·ª±a v√†o c·ªôt M√î T·∫¢), M√£ h√†ng (d·ª±a v√†o c·ªôt M√É H√ÄNG), S·ªë seri (d·ª±a v√†o c·ªôt IMEI), ƒê∆°n v·ªã t√≠nh, S·ªë l∆∞·ª£ng, v√† Ph·ª• ki·ªán (d·ª±a v√†o c·ªôt S·ªê L∆Ø·ª¢NG H√ÄNG T·∫†NG ho·∫∑c m√¥ t·∫£ th√™m).",
                    "X√°c ƒë·ªãnh r√µ r√†ng S·ªë ƒë·ªãnh danh ch√≠nh c·ªßa bi√™n b·∫£n (c√≥ th·ªÉ l√† S·ªë h·ª£p ƒë·ªìng, m√£ ƒë·ªÅ ngh·ªã, s·ªë PO). ƒê·ªìng th·ªùi x√°c ƒë·ªãnh *lo·∫°i* c·ªßa s·ªë ƒë·ªãnh danh n√†y (v√≠ d·ª•: H·ª£p ƒë·ªìng, PO, ƒê·ªÅ ngh·ªã, Kh√°c) d·ª±a v√†o c√°c c·ª•m t·ª´ ƒëi k√®m.",
                    "X√°c ƒë·ªãnh t√™n c√¥ng ty b√†n giao (B√™n A).",
                    "ƒê·∫£m b·∫£o ƒë·∫ßu ra JSON tu√¢n th·ªß c·∫•u tr√∫c ƒë∆∞·ª£c y√™u c·∫ßu trong prompt, s·ª≠ d·ª•ng c√°c vi·∫øt t·∫Øt: shd (cho gi√° tr·ªã s·ªë ƒë·ªãnh danh), shd_type (cho lo·∫°i s·ªë ƒë·ªãnh danh), cty, ds, ttb, model, hang, nsx, dvt, sl, seri, pk."
                ],
            )

            prompt ="""
D·ªØ li·ªáu ƒë·∫ßu ra d·∫°ng json.
Tr√≠ch xu·∫•t c√°c th√¥ng tin sau:
- S·ªë ƒë·ªãnh danh ch√≠nh c·ªßa bi√™n b·∫£n (c√≥ th·ªÉ l√† S·ªë h·ª£p ƒë·ªìng, s·ªë ƒë·ªÅ xu·∫•t, m√£ ƒë·ªÅ ngh·ªã ho·∫∑c s·ªë PO) (vi·∫øt t·∫Øt l√† shd, ch·ªâ 1 l·∫ßn xu·∫•t hi·ªán). Tr√≠ch xu·∫•t gi√° tr·ªã s·ªë ho·∫∑c m√£.
- Lo·∫°i c·ªßa s·ªë ƒë·ªãnh danh n√†y (v√≠ d·ª•: "H·ª£p ƒë·ªìng", "PO", "ƒê·ªÅ ngh·ªã", "Kh√°c") (vi·∫øt t·∫Øt l√† shd_type, ch·ªâ 1 l·∫ßn xu·∫•t hi·ªán). D·ª±a v√†o c√°c c·ª•m t·ª´ ƒëi k√®m nh∆∞ "Hƒê s·ªë:", "Theo Hƒê s·ªë:", "S·ªë H·ª£p ƒê·ªìng:", "D·ª±a theo Hƒê s·ªë:", "PO s·ªë:", "S·ªë PO:", "D·ª±a theo s·ªë PO:", "M√£ ƒë·ªÅ ngh·ªã:", "S·ªë ƒë·ªÅ xu·∫•t:". N·∫øu kh√¥ng r√µ lo·∫°i, d√πng "Kh√°c".
- T√™n c√¥ng ty b√™n giao (vi·∫øt t·∫Øt l√† cty, ch·ªâ hi·ªÉn th·ªã 1 l·∫ßn).
- Danh s√°ch thi·∫øt b·ªã (vi·∫øt t·∫Øt l√† ds), m·ªói thi·∫øt b·ªã trong danh s√°ch l√† m·ªôt ƒë·ªëi t∆∞·ª£ng json v·ªõi c√°c thu·ªôc t√≠nh:
  - T√™n thi·∫øt b·ªã (vi·∫øt t·∫Øt ttb).
  - Model (vi·∫øt t·∫Øt model).
  - H√£ng (vi·∫øt t·∫Øt hang).
  - N∆∞·ªõc s·∫£n xu·∫•t (vi·∫øt t·∫Øt nsx).
  - ƒê∆°n v·ªã t√≠nh (vi·∫øt t·∫Øt dvt).
  - S·ªë l∆∞·ª£ng (vi·∫øt t·∫Øt sl).
  - S·ªë seri (vi·∫øt t·∫Øt seri, ƒë·∫ßy ƒë·ªß th√¥ng tin nh∆∞ t·ªáp, n·∫øu c√≥ nhi·ªÅu seri cho 1 d√≤ng thi·∫øt b·ªã trong PDF th√¨ ƒë∆∞a v√†o m·∫£ng/list, n·∫øu ch·ªâ c√≥ 1 th√¨ l√† chu·ªói string, n·∫øu kh√¥ng c√≥ th√¨ ƒë·ªÉ tr·ªëng ho·∫∑c null).
  - Ph·ª• ki·ªán (vi·∫øt t·∫Øt l√† pk, chi ti·∫øt ph·ª• ki·ªán ho·∫∑c c·∫•u h√¨nh k·ªπ thu·∫≠t, d·ªØ li·ªáu d·∫°ng chu·ªói string, n·∫øu c√≥ nhi·ªÅu d√≤ng ph·ª• ki·ªán cho 1 thi·∫øt b·ªã th√¨ n·ªëi l·∫°i v√† xu·ªëng d√≤ng b·∫±ng '\n', n·∫øu kh√¥ng c√≥ th√¨ ƒë·ªÉ tr·ªëng ho·∫∑c null).

V√≠ d·ª• c·∫•u tr√∫c JSON mong mu·ªën:
{
  "shd": "Gi√° tr·ªã s·ªë/m√£",
  "shd_type": "H·ª£p ƒë·ªìng" ho·∫∑c "PO" ho·∫∑c "ƒê·ªÅ ngh·ªã" ho·∫∑c "Kh√°c",
  "cty": "...",
  "ds": [
    {
      "ttb": "...",
      "model": "...",
      "hang": "...",
      "nsx": "...",
      "dvt": "...",
      "sl": "...",
      "seri": "..." ho·∫∑c ["...", "..."] ho·∫∑c null,
      "pk": "G·ªìm:\n- Ph·ª• ki·ªán A (SL: ... ƒêVT: ...)\n- Ph·ª• ki·ªán B..." ho·∫∑c null
    },
    ...
  ]
}
"""
            response = model.generate_content([sample_pdf, prompt])

            try:
                 sample_pdf.delete()
                 print(f"File ƒë√£ x√≥a tr√™n Google AI: {sample_pdf.name}")
            except Exception as e:
                 print(f"L·ªói khi x√≥a file tr√™n Google AI: {e}")

        # --- X·ª≠ l√Ω ph·∫£n h·ªìi t·ª´ AI ---
        a = response.text.strip()
        if a.startswith("```json"):
            a = a[len("```json"):].strip()
        if a.endswith("```"):
             a = a[:-len("```")].strip()

        data = None
        try:
            data = json.loads(a)
            print("D·ªØ li·ªáu JSON nh·∫≠n ƒë∆∞·ª£c:", json.dumps(data, indent=2, ensure_ascii=False))

            extracted_shd = data.get('shd')
            extracted_shd_type = data.get('shd_type')
            print(f"Extracted shd value from AI: '{extracted_shd}' (Type: '{extracted_shd_type}')")

            if 'ds' not in data or not isinstance(data.get('ds'), list):
                 st.error("‚ùå Ph·∫£n h·ªìi t·ª´ AI kh√¥ng ch·ª©a danh s√°ch thi·∫øt b·ªã h·ª£p l·ªá ('ds'). Vui l√≤ng th·ª≠ l·∫°i v·ªõi file kh√°c ho·∫∑c ki·ªÉm tra n·ªôi dung file.", icon="‚ùå")
                 print(f"Ph·∫£n h·ªìi AI thi·∫øu kh√≥a 'ds' ho·∫∑c 'ds' kh√¥ng ph·∫£i list: {data}")
                 data = None
            if data and 'shd' not in data:
                 print(f"Ph·∫£n h·ªìi AI thi·∫øu kh√≥a 'shd', g√°n gi√° tr·ªã m·∫∑c ƒë·ªãnh.")
                 data['shd'] = ''
            if data and 'shd_type' not in data:
                 print(f"Ph·∫£n h·ªìi AI thi·∫øu kh√≥a 'shd_type', g√°n gi√° tr·ªã m·∫∑c ƒë·ªãnh.")
                 data['shd_type'] = 'Kh√°c'
            if data and 'cty' not in data:
                 print(f"Ph·∫£n h·ªìi AI thi·∫øu kh√≥a 'cty', g√°n gi√° tr·ªã m·∫∑c ƒë·ªãnh.")
                 data['cty'] = 'C√¥ng ty kh√¥ng r√µ'

            if data and 'ds' in data:
                data['ds'] = [item for item in data['ds'] if isinstance(item, dict)]
                if not data['ds']:
                     st.warning("‚ö†Ô∏è Danh s√°ch thi·∫øt b·ªã ('ds') tr√≠ch xu·∫•t ƒë∆∞·ª£c tr·ªëng ho·∫∑c kh√¥ng c√≥ m·ª•c h·ª£p l·ªá.", icon="‚ö†Ô∏è")
                     print("Danh s√°ch thi·∫øt b·ªã sau khi l·ªçc r·ªóng.")
                     data = None

        except json.JSONDecodeError as e:
            st.error(f"‚ùå L·ªói khi gi·∫£i m√£ JSON t·ª´ ph·∫£n h·ªìi AI: {e}. Ph·∫£n h·ªìi c√≥ th·ªÉ kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng JSON.", icon="‚ùå")
            st.text_area("Ph·∫£n h·ªìi g·ªëc t·ª´ AI:", a, height=200)
            print(f"Ph·∫£n h·ªìi AI g·ªëc g√¢y l·ªói JSON: {a}")
            data = None
        except Exception as e:
            st.error(f"‚ùå ƒê√£ c√≥ l·ªói kh√¥ng mong mu·ªën khi x·ª≠ l√Ω d·ªØ li·ªáu t·ª´ AI: {e}", icon="‚ùå")
            print(f"D·ªØ li·ªáu nh·∫≠n ƒë∆∞·ª£c tr∆∞·ªõc l·ªói: {data}")
            data = None

        # --- Logic g·ªôp thi·∫øt b·ªã v√† ƒëi·ªÅn v√†o Word ---
        if data and 'ds' in data and data['ds']:
            st.info("‚úçÔ∏è ƒêang t·∫°o file Word...", icon="‚è≥")
            try:
                # --- B∆Ø·ªöC 1: Nh√≥m c√°c thi·∫øt b·ªã V√Ä T√çNH T·ªîNG S·ªê L∆Ø·ª¢NG G·ªòP ---
                grouped_devices = {}

                for item in data['ds']:
                    group_key_parts = []
                    group_key_parts.append(standardize_string(item.get('ttb', '')).strip())
                    group_key_parts.append(str(item.get('model', '')).strip())
                    group_key_parts.append(str(item.get('hang', '')).strip())
                    group_key_parts.append(str(item.get('nsx', '')).strip())
                    group_key_parts.append(str(item.get('dvt', '')).strip())
                    group_key_parts.append(str(item.get('pk', '')).strip())

                    group_key = tuple(group_key_parts)

                    current_sl_raw = item.get('sl', '0')
                    current_sl = 0
                    try:
                        cleaned_sl_str = re.sub(r'[^\d.]', '', str(current_sl_raw).strip())
                        current_sl = float(cleaned_sl_str) if cleaned_sl_str else 0
                    except (ValueError, TypeError):
                        print(f"Warning: Could not convert item quantity '{current_sl_raw}' to number during grouping. Defaulting to 0.")
                        current_sl = 0

                    current_seri = item.get('seri', [])
                    if not isinstance(current_seri, list):
                        current_seri = [current_seri]
                    cleaned_current_seri = [str(s).strip() for s in current_seri if s is not None and str(s).strip() != '']

                    if group_key not in grouped_devices:
                        grouped_devices[group_key] = {
                            'ttb': str(item.get('ttb', '')).strip(),
                            'model': str(item.get('model', '')).strip(),
                            'hang': str(item.get('hang', '')).strip(),
                            'nsx': str(item.get('nsx', '')).strip(),
                            'dvt': str(item.get('dvt', '')).strip(),
                            'pk': str(item.get('pk', '')).strip(),
                            'total_sl': current_sl,
                            'seri': cleaned_current_seri
                        }
                    else:
                        grouped_devices[group_key]['total_sl'] += current_sl
                        existing_seri_set = set(grouped_devices[group_key]['seri'])
                        new_seri_to_add = [s for s in cleaned_current_seri if s and s not in existing_seri_set]
                        grouped_devices[group_key]['seri'].extend(new_seri_to_add)


                # B∆∞·ªõc 2: Chuy·ªÉn ƒë·ªïi dictionary nh√≥m th√†nh danh s√°ch cu·ªëi c√πng
                final_device_list = []
                for key, grouped_item in grouped_devices.items():
                    seri_string = ''
                    if grouped_item['seri']:
                         unique_seri = sorted(list(set(grouped_item['seri'])))
                         seri_string = 'S·ªë seri: ' + ', '.join(unique_seri)
                    else:
                        seri_string = 'S·ªë seri: Kh√¥ng c√≥'

                    final_device_list.append({
                        'ttb': grouped_item['ttb'],
                        'model': grouped_item['model'],
                        'hang': grouped_item['hang'],
                        'nsx': grouped_item['nsx'],
                        'dvt': grouped_item['dvt'],
                        'sl': grouped_item['total_sl'],
                        'pk': grouped_item['pk'],
                        'seri_text': seri_string
                    })

                # B∆∞·ªõc 3: ƒêi·ªÅn d·ªØ li·ªáu v√†o b·∫£ng Word
                try:
                     document = Document('bbbg.docx')
                except Exception as e:
                     st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y ho·∫∑c kh√¥ng m·ªü ƒë∆∞·ª£c file m·∫´u 'bbbg.docx'. Vui l√≤ng ƒë·∫£m b·∫£o file n√†y n·∫±m c√πng th∆∞ m·ª•c v·ªõi script.", icon="‚ùå")
                     raise e

                font_name= 'Times New Roman'
                font_size=12

                print("\n--- C·∫•u tr√∫c Paragraphs v√† Runs trong bbbg.docx ---")
                try:
                    for i, paragraph in enumerate(document.paragraphs):
                        print(f"Paragraph {i}: '{paragraph.text.strip()}'")
                        for j, run in enumerate(paragraph.runs):
                            print(f"  Run {j}: '{run.text}' (Length: {len(run.text)})")
                    print("-----------------------------------------------\n")
                except Exception as e:
                    print(f"L·ªói khi in c·∫•u tr√∫c Paragraphs v√† Runs: {e}")


                try:
                    table = document.tables[0]
                except IndexError:
                     st.error("‚ùå File m·∫´u 'bbbg.docx' kh√¥ng ch·ª©a b·∫£ng n√†o.", icon="‚ùå")
                     raise IndexError

                if len(table.rows) > 1:
                    rows_to_remove_indices = range(len(table.rows) - 1, 0, -1)
                    for i in rows_to_remove_indices:
                        row = table.rows[i]
                        try:
                            tbl = row._tbl
                            tbl.getparent().remove(tbl)
                        except Exception as e:
                            print(f"L·ªói khi x√≥a h√†ng {i} trong b·∫£ng m·∫´u: {e}")

                count=0
                for item in final_device_list:
                    count += 1
                    ttb_text = str(item.get('ttb', '')).strip()
                    model_text = str(item.get('model', '')).strip()
                    hang_text = str(item.get('hang', '')).strip()
                    nsx_text = str(item.get('nsx', '')).strip()
                    dvt_text = str(item.get('dvt', '')).strip()
                    sl_text = str(int(item.get('sl', 0))).strip() if item.get('sl') is not None else ""
                    pk_text = str(item.get('pk', '')).strip()

                    device_info_text = f"{ttb_text}\n H√£ng: {hang_text}\n NSX: {nsx_text}\n Model: {model_text}"
                    if pk_text:
                         device_info_text += f"\n{pk_text}"
                    else:
                         device_info_text += f"\nPh·ª• ki·ªán: Kh√¥ng c√≥"

                    new_device = [str(count),
                                  device_info_text,
                                  dvt_text,
                                  sl_text,
                                  item['seri_text']
                                 ]

                    row = table.add_row()
                    for i, cell_text in enumerate(new_device):
                        if i in (0, 2, 3):
                            ali = WD_ALIGN_PARAGRAPH.CENTER
                        else:
                            ali = WD_ALIGN_PARAGRAPH.LEFT
                        try:
                            cell = row.cells[i]
                            cell.text = str(cell_text)
                            for paragraph in cell.paragraphs:
                                paragraph.alignment = ali
                                for run in paragraph.runs:
                                    run.font.name = font_name
                                    run.font.size = Pt(font_size)
                        except IndexError:
                            st.warning(f"‚ö†Ô∏è L·ªói: B·∫£ng trong file m·∫´u c√≥ √≠t h∆°n {len(new_device)} c·ªôt ({len(row.cells)}). Kh√¥ng th·ªÉ ƒëi·ªÅn d·ªØ li·ªáu ƒë·∫ßy ƒë·ªß cho h√†ng thi·∫øt b·ªã th·ª© {count}.", icon="‚ö†Ô∏è")
                            print(f"L·ªói: H√†ng {count} c√≥ {len(row.cells)} √¥, nh∆∞ng d·ªØ li·ªáu c√≥ {len(new_device)} m·ª•c.")
                            pass

                # --- T√¨m v√† thay th·∫ø placeholder cho S·ªë h·ª£p ƒë·ªìng (ƒê·ªäNH D·∫†NG THEO LO·∫†I) ---
                shd_value_raw = data.get('shd')
                shd_type_raw = data.get('shd_type')

                shd_value = str(shd_value_raw).strip() if shd_value_raw is not None else ''
                shd_type = str(shd_type_raw).strip() if shd_type_raw is not None else 'Kh√°c'

                shd_value_to_replace = ''

                if shd_value:
                    shd_type_lower = shd_type.lower()

                    if 'h·ª£p ƒë·ªìng' in shd_type_lower or 'hd' in shd_type_lower:
                        shd_value_to_replace = f"D·ª±a theo Hƒê s·ªë: {shd_value}"
                    elif 'po' in shd_type_lower or 'ƒë·ªÅ ngh·ªã' in shd_type_lower or 'denghi' in shd_type_lower or 'm√£ ƒë·ªÅ ngh·ªã' in shd_type_lower:
                        shd_value_to_replace = f"D·ª±a theo PO: {shd_value}"
                    else:
                        shd_value_to_replace = f"D·ª±a theo s·ªë: {shd_value}"

                print(f"Value to replace placeholder with: '{shd_value_to_replace}' (Derived from value: '{shd_value}', type: '{shd_type}')")


                shd_placeholder_replaced = False
                shd_pattern = re.compile(re.escape("shd"), re.IGNORECASE)

                for paragraph in document.paragraphs:
                     if shd_pattern.search(paragraph.text):
                          for run in paragraph.runs:
                               original_run_text = run.text
                               new_run_text = shd_pattern.sub(shd_value_to_replace, original_run_text)

                               if new_run_text != original_run_text:
                                    run.text = new_run_text
                                    shd_placeholder_replaced = True

                if not shd_placeholder_replaced:
                     st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y placeholder 'shd' (ho·∫∑c 'SHD',...) trong c√°c ƒëo·∫°n vƒÉn c·ªßa file m·∫´u. S·ªë h·ª£p ƒë·ªìng s·∫Ω kh√¥ng ƒë∆∞·ª£c ƒëi·ªÅn v√†o file Word.", icon="‚ö†Ô∏è")
                     print("Kh√¥ng t√¨m th·∫•y placeholder 'shd' (ho·∫∑c 'SHD',...).")

                # --- K·∫æT TH√öC LOGIC THAY TH·∫æ PLACEHOLDER (ƒê·ªäNH D·∫†NG THEO LO·∫†I) ---

                # --- T·∫°o t√™n file ƒë·∫ßu ra theo y√™u c·∫ßu m·ªõi ---
                # Format: {Quantity}{DeviceName}-{Quantity}{DeviceName}_{ShortCompanyName}_{SHDValuePart}

                # 1. Chu·ªói th√¥ng tin thi·∫øt b·ªã (S·ªë l∆∞·ª£ng + T√™n thi·∫øt b·ªã cho m·ªói lo·∫°i g·ªôp)
                device_info_filename_parts = []
                for item in final_device_list:
                    quantity = int(item.get('sl', 0))
                    formatted_quantity = f"{quantity:02d}" if quantity >= 0 else "00"
                    device_name = str(item.get('ttb', '')).strip()

                    cleaned_device_name_part = re.sub(r'[\\/*?":<>|{}\[\]().,_]', '', device_name).strip()

                    if cleaned_device_name_part:
                         device_info_filename_parts.append(f"{formatted_quantity} {cleaned_device_name_part}")

                device_info_string_for_filename = "-".join(device_info_filename_parts)

                # 2. L·∫•y v√† r√∫t g·ªçn t√™n c√¥ng ty (B√™n giao)
                cty_name_raw = data.get('cty', 'UnknownCompany')
                cty_name_full = str(cty_name_raw).strip() if cty_name_raw is not None else 'UnknownCompany'
                cleaned_cty_name = shorten_company_name(cty_name_full)

                if not cleaned_cty_name:
                    cleaned_cty_name = re.sub(r'[\\/*?":<>|{}\[\]()]', '', cty_name_full).strip(" ,.-_&")


                # 3. L·∫•y gi√° tr·ªã SHD (ch·ªâ ph·∫ßn s·ªë/m√£ tr∆∞·ªõc d·∫•u g·∫°ch ngang n·∫øu c√≥)
                shd_value_for_filename = shd_value

                shd_parts = shd_value_for_filename.split('-', 1)
                shd_cleaned_filename_part = shd_parts[0].strip() if shd_parts and shd_parts[0].strip() else ''

                shd_cleaned_filename_part = clean_filename(shd_cleaned_filename_part)


                # 4. K·∫øt h·ª£p c√°c ph·∫ßn v√† l√†m s·∫°ch t√™n file l·∫ßn cu·ªëi
                part1 = device_info_string_for_filename if device_info_string_for_filename else "ThietBi"
                part2 = cleaned_cty_name if cleaned_cty_name else "CongTy"
                part3 = shd_cleaned_filename_part if shd_cleaned_filename_part else "SoDinhDanh"

                raw_output_filename = f"{part1}_{part2}_{part3}"

                output_filename_final = clean_filename(raw_output_filename)

                if not output_filename_final.lower().endswith('.docx'):
                     output_filename = output_filename_final + '.docx'
                else:
                     output_filename = output_filename_final

                if not output_filename or output_filename.lower() == '.docx' or len(output_filename) < (len(".docx") + 3):
                    fallback_shd_part = shd_cleaned_filename_part if shd_cleaned_filename_part else "NoID"
                    fallback_cty_part = cleaned_cty_name if cleaned_cty_name else "CongTy"
                    output_filename = f"BienBanBanGiaoNoiBo_Fallback_{fallback_cty_part}_{fallback_shd_part}.docx"


                print(f"Generated output filename: {output_filename}")

                # --- K·∫æT TH√öC T·∫†O T√äN FILE ƒê·∫¶U RA ---


                byte_io = BytesIO()
                document.save(byte_io)
                byte_io.seek(0)

                st.download_button(
                    label="‚úÖ T·∫£i xu·ªëng file Word Bi√™n b·∫£n b√†n giao n·ªôi b·ªô",
                    data=byte_io,
                    file_name=output_filename,
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                )

                st.success(f"üéâ ƒê√£ x·ª≠ l√Ω file PDF v√† t·∫°o Bi√™n b·∫£n b√†n giao n·ªôi b·ªô: **{output_filename}**", icon="‚úÖ")

            except Exception as e:
                 st.error(f"‚ùå ƒê√£ c√≥ l·ªói x·∫£y ra trong qu√° tr√¨nh t·∫°o file Word: {e}", icon="‚ùå")
                 print(f"L·ªói x·ª≠ l√Ω Word: {e}")

        elif data is not None:
             st.warning("‚ö†Ô∏è Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c danh s√°ch thi·∫øt b·ªã n√†o t·ª´ file PDF.", icon="‚ö†Ô∏è")
             print("Danh s√°ch thi·∫øt b·ªã 'ds' tr·ªëng ho·∫∑c kh√¥ng h·ª£p l·ªá.")

    except Exception as e:
        st.error(f"‚ùå ƒê√£ c√≥ l·ªói x·∫£y ra trong qu√° tr√¨nh x·ª≠ l√Ω file: {e}", icon="‚ùå")
        print(f"L·ªói chung khi x·ª≠ l√Ω file: {e}")

    finally:
        if temp_file_path and os.path.exists(temp_file_path):
            try:
                os.remove(temp_file_path)
                print(f"File t·∫°m ƒë√£ x√≥a: {temp_file_path}")
            except Exception as e:
                st.warning(f"‚ö†Ô∏è L·ªói khi x√≥a file t·∫°m th·ªùi: {e}", icon="‚ö†Ô∏è")
                print(f"L·ªói x√≥a file t·∫°m: {e}")

else:
    st.info("‚¨ÜÔ∏è Vui l√≤ng ch·ªçn m·ªôt file PDF ƒë·ªÉ b·∫Øt ƒë·∫ßu.", icon="üìÑ")